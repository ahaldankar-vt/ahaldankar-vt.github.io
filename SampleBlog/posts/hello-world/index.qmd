---
title: This is a dummy blog posts
date: '2022-06-01'
categories:
  - '123'
  - Second Tag
description: 'This is a test post. In this post, I try out different functionalities'
execute:
  message: false
  warning: false
editor_options:
  chunk_output_type: console
jupyter: python3
---

# Get and examine data

## Download data

```{python}
# Necessary data science packages
import sys
from packaging import version
import sklearn
import sklearn.datasets
import pandas as pd
import numpy as np

wine_dataset = sklearn.datasets.load_wine()
wine_df = pd.DataFrame(data=wine_dataset.data, columns=wine_dataset.feature_names)
wine_df['labels'] = wine_dataset['target'] # Also add the labels associated with each sample

# Added code - maybe take out. 
X, y = wine_dataset.data, wine_dataset.target
X
```

```{python}
#| scrolled: true
X.shape
```

```{python}
y
```

```{python}
y.shape
```

## Inspect the data

```{python}
# Display the head of the wine dataframe. 
wine_df.head()
```

```{python}
# Display column names and types
wine_df.info()
```

```{python}
# Get the value counts for each different type of wine. 
wine_df['labels'].value_counts()
```

It seems that the labels are roughly balanced, although wine type #1 is the most common. Now, let's do a train-test split. 

```{python}
def shuffle_and_split_data(data, test_ratio):
    shuffled_indices = np.random.permutation(len(data))
    test_set_size = int(len(data) * test_ratio)
    test_indices = shuffled_indices[:test_set_size]
    train_indices = shuffled_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]
```

```{python}
train_set, test_set = shuffle_and_split_data(wine_df, 0.2)
len(train_set)
```

```{python}
# Allows results of the notebook to be reproducible. 
np.random.seed(42)
```

```{python}
len(test_set)
```

## Train Test Split

```{python}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

```{python}
X_train.shape
X_test.shape
y_train.shape
y_test.shape
```

## Training and Predictions

We have successfully performed a train-test split with 143 samples in the training set and 35 samples in the test set.
Since we are dealing with a small dataset for multi-class classification, it might be helpful to use the SVM classifier. 

```{python}
from sklearn.svm import SVC

# Instantiate and fit on the training set. 
svm_clf = SVC(random_state=42)
svm_clf.fit(X_train, y_train)
```

```{python}
# Predict on the testing set. 
predictions = svm_clf.predict(X_test)
```

```{python}
# Now, let's evaluate the accuracy of the predictions. 
from sklearn.metrics import accuracy_score as accuracy
round(accuracy(y_test, predictions), 2)
```

We get an accuracy of around 71%. Let's plot our results in a confusion matrix. 

```{python}
from sklearn import metrics
from sklearn.metrics import ConfusionMatrixDisplay

conf_matrix = metrics.confusion_matrix(y_test, predictions)
cm = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0,1,2])
cm.plot()
```


