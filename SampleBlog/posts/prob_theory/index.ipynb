{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: This is a blog post on probability theory and random variables.\n",
        "date: '2023-11-03'\n",
        "categories:\n",
        "  - 'Probability Theory, Random Variables, Naive Bayes'\n",
        "description: 'This is a blog post on probability theory. Specifically, the Naive Bayes classifier is used.'\n",
        "execute:\n",
        "  message: false\n",
        "  warning: false\n",
        "editor_options:\n",
        "  chunk_output_type: console\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this blog post, we will investigate the Seaborn Attention dataset. Specifically, we will focus on using the Naive Bayes classifier to predict whether a test-taker is focused or not depending on their score. \n",
        "\n",
        "# Get and Examine the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "sns.get_dataset_names()\n",
        "attention_raw = sns.load_dataset('attention')\n",
        "attention_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attention_raw.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's drop the Unnamed column, since it will not help with our analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attention = attention_raw.drop(\"Unnamed: 0\", axis=1)\n",
        "attention.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's explore the dataset and see if there are any missing/outlier values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attention.isna().any().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attention.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "[attention['subject'].min(), attention['subject'].max()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "[attention['solutions'].min(), attention['solutions'].max()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "[attention['score'].min(), attention['score'].max()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like there are 20 subjects total, who were given 3 different tests. From each of these tests, the score of the subjects was computed. The minimum score across all tests was 2.0, while the maximum score was 9.0. Presumably, the test was ranked on a scale of 1 to 10. \n",
        "\n",
        "TODO: Find better documentation on this dataset. \n",
        "\n",
        "# Visualizations\n",
        "\n",
        "Let's now visualize the attention dataset, by plotting the distribution of participant scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.barplot(data=attention, x='subject', y='score');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that some subjects performed better than others. Let's visualize which of the subjects were focused and which were distracted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.barplot(data=attention, x='subject', y='score', hue='attention');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that, on average, focused subjects appeared to perform better than non-focused subjects. Let's confirm this hypothesis by computing the average scores for the divided and focused groups. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avg_scores = pd.DataFrame(attention.groupby('attention').mean()['score'])\n",
        "avg_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Indeed, we can see that the average score for divided users is around 5, while the average score for focused users is approximately 6.8. It appears that the average test score for focused users is almost 2 points higher than that of distracted users.  \n",
        "\n",
        "# Naive Bayes Classifier\n",
        "\n",
        "Let's now use a Naive Bayes classifier to predict whether a participant is distracted or not based on their score. We can drop the other columns, since they won't be relevant.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "attention_nb = attention[['attention', 'score']]\n",
        "attention_nb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, perform a train-test split. Since the dataset is small, let's choose 80% of the samples to be in the training set and 20% of the samples to be in the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = attention_nb[['score']]\n",
        "y = attention_nb['attention']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train.shape\n",
        "X_test.shape\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's instantiate the model and fit the data to the model. We will use a Gaussian Naive Bayes classifier, which assumes that the distribution of continuous features is Gaussian. This appears to be a reasonable assumption in the case of the test scores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_gauss = GaussianNB()\n",
        "nb_gauss.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's evaluate the accuracy on our testing set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions = nb_gauss.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "round(accuracy(y_test, predictions), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "75% is actually quite good, considering how few samples were used to train the model. We can plot a confusion matrix to get a better sense for which samples the model misclassified. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "labels_arr = ['divided', 'focused']\n",
        "conf_matrix = metrics.confusion_matrix(y_test, predictions, labels=labels_arr)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['divided', 'focused'])\n",
        "cm.plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that the Gaussian NB classifier over-predicted samples as being focused. The three samples in the upper right quadrant were predicted as being focused, but were in fact divided. \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}