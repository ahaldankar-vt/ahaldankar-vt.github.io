{
  "hash": "8ea18e010b195a4e8297ab9dd1aaa723",
  "result": {
    "markdown": "---\ntitle: This is a blog post on probability theory and random variables.\ndate: '2023-11-03'\ncategories:\n  - 'Probability Theory, Random Variables, Naive Bayes'\ndescription: 'This is a blog post on probability theory. Specifically, the Naive Bayes classifier is used.'\nexecute:\n  message: false\n  warning: false\neditor_options:\n  chunk_output_type: console\n---\n\nIn this blog post, we will investigate the Seaborn Attention dataset. Specifically, we will focus on using the Naive Bayes classifier to predict whether a test-taker is focused or not depending on their score. \n\n# Get and Examine the Data\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nsns.get_dataset_names()\nattention_raw = sns.load_dataset('attention')\nattention_raw.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>subject</th>\n      <th>attention</th>\n      <th>solutions</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nattention_raw.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 60 entries, 0 to 59\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   Unnamed: 0  60 non-null     int64  \n 1   subject     60 non-null     int64  \n 2   attention   60 non-null     object \n 3   solutions   60 non-null     int64  \n 4   score       60 non-null     float64\ndtypes: float64(1), int64(3), object(1)\nmemory usage: 2.5+ KB\n```\n:::\n:::\n\n\nLet's drop the Unnamed column, since it will not help with our analysis. \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nattention = attention_raw.drop(\"Unnamed: 0\", axis=1)\nattention.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>attention</th>\n      <th>solutions</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>divided</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLet's explore the dataset and see if there are any missing/outlier values. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nattention.isna().any().any()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nFalse\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nattention.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(60, 4)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n[attention['subject'].min(), attention['subject'].max()]\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n[1, 20]\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n[attention['solutions'].min(), attention['solutions'].max()]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n[1, 3]\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n[attention['score'].min(), attention['score'].max()]\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n[2.0, 9.0]\n```\n:::\n:::\n\n\nIt looks like there are 20 subjects total, who were given 3 different tests. From each of these tests, the score of the subjects was computed. The minimum score across all tests was 2.0, while the maximum score was 9.0. Presumably, the test was ranked on a scale of 1 to 10. \n\nTODO: Find better documentation on this dataset. \n\n# Visualizations\n\nLet's now visualize the attention dataset, by plotting the distribution of participant scores.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nsns.barplot(data=attention, x='subject', y='score');\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=576 height=429}\n:::\n:::\n\n\nIt appears that some subjects performed better than others. Let's visualize which of the subjects were focused and which were distracted. \n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsns.barplot(data=attention, x='subject', y='score', hue='attention');\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=576 height=429}\n:::\n:::\n\n\nIt appears that, on average, focused subjects appeared to perform better than non-focused subjects. Let's confirm this hypothesis by computing the average scores for the divided and focused groups. \n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\navg_scores = pd.DataFrame(attention.groupby('attention').mean()['score'])\navg_scores\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n    <tr>\n      <th>attention</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>divided</th>\n      <td>5.116667</td>\n    </tr>\n    <tr>\n      <th>focused</th>\n      <td>6.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIndeed, we can see that the average score for divided users is around 5, while the average score for focused users is approximately 6.8. It appears that the average test score for focused users is almost 2 points higher than that of distracted users.  \n\n# Naive Bayes Classifier\n\nLet's now use a Naive Bayes classifier to predict whether a participant is distracted or not based on their score. We can drop the other columns, since they won't be relevant.  \n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nattention_nb = attention[['attention', 'score']]\nattention_nb.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attention</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>divided</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>divided</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>divided</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>divided</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>divided</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNext, perform a train-test split. Since the dataset is small, let's choose 80% of the samples to be in the training set and 20% of the samples to be in the test set. \n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = attention_nb[['score']]\ny = attention_nb['attention']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nX_train.shape\nX_test.shape\ny_train.shape\ny_test.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n(12,)\n```\n:::\n:::\n\n\nNow, let's instantiate the model and fit the data to the model. We will use a Gaussian Naive Bayes classifier, which assumes that the distribution of continuous features is Gaussian. This appears to be a reasonable assumption in the case of the test scores. \n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.naive_bayes import GaussianNB\n\nnb_gauss = GaussianNB()\nnb_gauss.fit(X_train, y_train);\n```\n:::\n\n\nLet's evaluate the accuracy on our testing set. \n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\npredictions = nb_gauss.predict(X_test)\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.metrics import accuracy_score as accuracy\nround(accuracy(y_test, predictions), 2)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n0.75\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\npredictions\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\narray(['divided', 'divided', 'focused', 'focused', 'focused', 'focused',\n       'focused', 'focused', 'focused', 'focused', 'focused', 'focused'],\n      dtype='<U7')\n```\n:::\n:::\n\n\n75% is actually quite good, considering how few samples were used to train the model. We can plot a confusion matrix to get a better sense for which samples the model misclassified. \n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nfrom sklearn import metrics\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nlabels_arr = ['divided', 'focused']\nconf_matrix = metrics.confusion_matrix(y_test, predictions, labels=labels_arr)\ncm = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['divided', 'focused'])\ncm.plot();\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-20-output-1.png){width=531 height=434}\n:::\n:::\n\n\nIt appears that the Gaussian NB classifier over-predicted samples as being focused. The three samples in the upper right quadrant were predicted as being focused, but were in fact divided. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}